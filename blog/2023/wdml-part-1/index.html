<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>What do models learn? (Part 1) | Paul  Grosu</title>
    <meta name="author" content="Paul  Grosu">
    <meta name="description" content="This is the first of a multi-part blog trying to dive a bit deeper regarding what machine learning models actually learn from the data that they are being trained on.">
    <meta name="keywords" content="Paul Grosu, Genomics, Machine Learning, Artificial Intelligence">


    <!-- Bootstrap & MDB -->
    <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
    <!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/paul_grosu_photo.jpg?bf5f93dfc1b8b6489cf0316b74964d68">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://pgrosu.github.io/blog/2023/wdml-part-1/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script>
    <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpubnoa/template.v2.js"></script>
    <script src="/assets/js/distillpubnoa/transforms.v2.js"></script>
    <script src="/assets/js/distillpubnoa/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "What do models learn? (Part 1)",
      "description": "This is the first of a multi-part blog trying to dive a bit deeper regarding what machine learning models actually learn from the data that they are being trained on.",
      "published": "October 18, 2023",
      "authors": [
        {
          "author": "Paul Grosu",
          "authorURL": "https://pgrosu.github.io/",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Paul </span>Grosu</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>What do models learn? (Part 1)</h1>
        <p>This is the first of a multi-part blog trying to dive a bit deeper regarding what machine learning models actually learn from the data that they are being trained on.</p>
      </d-title><d-byline></d-byline><d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#problem-state-representation-through-values">Problem State Representation Through Values</a></div>
            <div><a href="#identifying-state-separation-in-data">Identifying State Separation in Data</a></div>
            <div><a href="#the-mathematical-neuron-model-58-the-perceptron">The Mathematical Neuron Model: The Perceptron</a></div>
            
          </nav>
        </d-contents>

        <p>Today’s machine learning and artificial intelligence (AI) domains dominate the landscape of many industries, where the question usually is <em>“what more can we do with data to accomplish some goal?”</em>, which is fed into a complex model to match against a specific pattern.  Such models are so well optimized with so many layers to focus them towards a specific patterned goal, that the internals are difficult to explain.  So when asked <em>“<ins>how does this model perform this goal, and what has it learned from the data</ins>“</em>, those questions are becoming more difficult to answer through clear and simple concepts.  Throughout this series of blogs I am hoping to uncover this for a wide audience – with any complex mathematics gently explained through simple analogies – as I keep running into these questions, but have not seen them well-presented without losing the reader through obscure, domain-specific terminology.  These topics will be divided into bite-size blogs, so as to not to overwhelm the reader or lose any audience members.  I will try to apply it to multiple fields as to make the material welcome to a variety of wide breadth of interested readers.  I will begin with a focus around the area of Deep Learning, which has become mysterious to many to explain precisely the meaning behind the effect of how they internally operate on the data to provide the given results.  With time I will expand to other areas of machine learning and artificial intelligence.</p>

<h2 id="problem-state-representation-through-values">Problem State Representation Through Values</h2>

<p>Most problems are easiest defined by the state they present themselves in.  The easist way to communicate that state is through values, and the connections among values.  The reason values present the best representation is because the analysis of values provides the best flexibility with our current domain knowledge towards insight of transforming problems towards solutions.  The simplest types of data types are either qualitative or quantitative, as shown in the table below:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/data_types.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 1: The different attributes in the types of data representation.  Such data would then be able to be processed a little bit more systematically via formal methods of calculation and transformation.
</div>

<p>As an example of a dataset to start with, let’s use the following simulated data of patients’ temperature and condition.  We will eventually build a model that will predict using temperature if they might be either sick or healthy.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/patient_data.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 2: This is a simple example of simulated patient data to model the predicatability of patient health based on temperature.
</div>

<p>Assuming the data is <em>clean</em> – a topic I will cover at a later time – we can assume there is very little variability in the representation of the data and the reality of the true model the data captured.  One has to assume there is a model operating in nature that we inspect with our instruments, to capture the representation of its state in the form of values.  If there are minimal perturbations between the model and the instruments capturing its state, we assume the data contains minimal noise (error).  For now we will assume that in order to capture the larger concepts of a simple model.</p>

<h2 id="identifying-state-separation-in-data">Identifying State Separation in Data</h2>

<p>In our simple example, we simulated body temperature in trying to predict the state of patients (i.e. sick or healthy).  The simplest approach to start with is to plot the data, and see what trends might exist:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/example_data_patient_state.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 3: This is a plot of the patient data vs body temperature.  A clear trend separation exists.
</div>

<p>A clear nice vertical separation between the healthy and sick patients exists at a threshold value of 100° F:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/example_data_threshold.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 4: A clear threshold of 100° F patient data vs body temperature, giving a simple, clear trend separation between sick and healthy patients.
</div>

<p>Of course this is a very simple threshold that had chosed based on visual inspection, but it will help us with demonstrating the next step in the model.  More complex models will be presented later where a clear threshold will be a bit more difficult to select for.</p>

<p>One thing that would make the separation a little easier to manage is to rescale the data between 0 and 1.  The simplest approach would be to divide the input values by 100 (or multiply by 1/100) and then substract 0.5.  Then the threshold value can be 0.5, and then we can label anything above 0.5 with a 1 (<i><b style="color:red">sick</b></i>), and anything below with 0 (<i><b style="color:green">healthy</b></i>).</p>

<h2 id="the-mathematical-neuron-model-the-perceptron">The Mathematical Neuron Model: The Perceptron</h2>

<p>Most models today apply a concept of <i>Deep Learning</i> upon data to learn similar to how our brains function.  The idea came from studying how our brains work.  The general concept is that we have at the core neurons, that receive an input signal and produce an output signal as follows:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/a_neuron.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 5: The neuron schematic as it operates in the brain.
</div>

<p>A neuron receives input signals from other connected neurons, and traverses the axon to generate an output signal.  Our brains have many layers of connected neurons to perform a decision or identify a pattern:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/neuron_layers.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 6: Neurons are organized into layers communicating in complex patters with each other to perform specific tasks.
</div>

<p>Given the above, a neuroscientist and a logician – namely Warren S. McCulloch and Walter Pitts – wrote a paper in 1943 called <em>“A logical calculus of the ideas immanent in nervous activity”</em> in the Bulletin of Mathematical Biophysics<d-cite key="mccullochpitts1943neuronmodel"></d-cite>.  They tried to mathematically model the workings of a neuron, which Frank Rosenblatt defined as a perceptron in his 1958 <em>Psychological Review</em> paper<d-cite key="rosenblatt1958perceptron"></d-cite>:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/the_perceptron.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 7: The perceptron defined based on the mathematical modeling of the neuron by McCulloch, Pitts and Rosenblatt.
</div>

<p>The idea is that the inputs (temperature) can be multiplied by adjusted weights and then summed up – via the <em><ins>adder function</ins></em> – such that based on a threshold (<em><ins>activation function</ins></em>) the output (sick or healthy) can be determined.  The mathematical representation of this would be as follows:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/the_perceptron_equation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 8: The mathematical model of the perceptron, where the output would be run through a threshold function.  The last term (weight<sub>0</sub>) is usually called the bias term in order to fine-tune adjust the accuracy of the separation among the labels (sick vs healthy).
</div>

<p>The threshold function operates in our case by activating to the appropriate output based in the given input:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/threshold_function.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 9: The threshold function of activating according to the given input.
</div>

<p>The idea is that the inputs (temperature) can be multiplied by adjusted weights and then summed up – via the <em><ins>adder function</ins></em> – such that based on a threshold (<em><ins>activation function</ins></em>) the output (sick or healthy) can be determined.  The mathematical representation of this would be as follows:</p>

<p>For our patient example, the perceptron model can be simplified to the following:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/the_perceptron_patient_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 10: The perceptron model of the patient example dataset.
</div>

<p>The above perceptron usually is presented in the following compacted form (which we will use from now on):</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/collapsed_perceptron.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 11: The compact form of the perceptron model for our patient example.
</div>

<p>The next question for extending our model to make it more useful would be to answer the following question: “<em>Should the patient be provided an aspirin regimen or not?</em>”.  This is based on the assumption that the model assumes this whole decision is based only on body temperature.  The way we can do this is to extend the model by a deeper layer with another perceptron:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/two_layer_network.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 11: A two layered neural network for extending the original perceptron with the discriminator for administering aspirin or not.  The weights for the second perceptron would be <i>w<sub>1</sub>=1</i> and <i>w<sub>0</sub>=0</i>.
</div>

<p>We have now created our first neural network – or simple deep neural network – but the question we still need to answer is, what did this neural network learn?  In short what these weights perform is the neuronal firing pattern to label across a <em><ins>decision boundary</ins></em> either <em>sick</em> or <em>healthy</em>.  This is driven by the pattern in the input data – thus the input data decides which neurons should fire, activating those weights.  But still, that feels confusing!</p>

<p>If we look carefully at the behavior of these weights, they act as <i>vectors</i> – something I’ll cover later in greater detail – to rescale the space the data is represented in, in order to have a better separation criteria for selecting between the sick and healthy category (label) for each patient.  So <em>w<sub>1</sub>=1/100</em> re-adjusts all the values – together with the <i>bias</i> term (<em>w<sub>0</sub>=-0.5</em>) – to fall roughly between 0 and 1 by ensuring that values less than 100 fall below the 0.5 threshold, while anything above are over 0.5.  If you look carefully, the decision boundary of <em>Temperature=100</em> (or <em>x=0.5</em> after rescaling) is at a 90° (right angle) to the points:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/2023-10-18-wdml-part-1/decision_boundary_90_degrees.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 12: The weight vectors of *w<sub>1</sub>=1/100* and *w<sub>0</sub>=-0.5* rescale and shift the temperature space (x-coordinate space).
</div>

<p>What this rescaling of the space actually does, sets the minimum input activation value (of 100° F) for activating the decision towards sickness.  If the input is below the threshold of 100° F, the perceptron is below the activation barrier of labeling the patient into the sick region of the space, thus remaining within the healthy region of the space.</p>

<p>Thus a model in the most simple terms reshapes the data as a whole (in order to preserve its representation of reality) for properly finding discriminating lines for creating labeling boundaries.  These labeled boundaries then become the categories (labels) for classifying the input data into a decision about how to move forward based on this information.</p>

<p>We will explore each of these ideas in greater depth in the upcoming blogs, but I hope this gives you a glimpse of what models actually learn about the data they are trained upon.</p>

<!---
## References

1. W.S. McCulloch and W. Pitts. A logical calculus of ideas imminent in nervous activity.
Bulletin of Mathematics Biophysics, 5:115–133, 1943.

2. F. Rosenblatt. The Perceptron: A probabilistic model for information storage and
organization in the brain. Psychological Review, 65(6):386–408, 1958.
-->

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2023-10-18-wdml-part-1.bib"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Paul  Grosu. • E-Mail <a href="mail:pgrosu@gmail.com" target="_blank">pgrosu@gmail.com</a> • LinkedIn: <a href="https://www.linkedin.com/in/paul-grosu-6262807/" target="_blank" rel="external nofollow noopener">https://www.linkedin.com/in/paul-grosu-6262807/</a>

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="/assets/js/bootstrap.bundle.min.js"></script>
  <!-- <script src="/assets/js/mdb.min.js"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
